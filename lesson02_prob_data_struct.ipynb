{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lesson 02: Probabilistic Data Structures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Probabilistic Data Structures](http://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/) are a fascinating and relatively new area of algorithms... largely pioneered by just a few individuals \u2013 e.g., [Philippe Flagolet](http://algo.inria.fr/flajolet/). Lately these have been finding oh so many uses, particularly for analytics with large-scale data and streaming use cases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When you have a spare hour, definitely check out this O'Reilly webcast, [Probabilistic Data Structures and Breaking Down Big Sequence Data](http://www.oreilly.com/pub/e/1784) by C. Titus Brown:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<iframe allowfullscreen=\"allowfullscreen\" frameborder=\"0\" height=\"315\" src=\"//www.youtube.com/embed/M3O5YRS4_kY\" width=\"560\"> </iframe>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll need plenty of interesting data to illustrate how to use these kinds of algorithms... Let's create a data set from the text of the [Jabberwocky poem](http://www.jabberwocky.com/carroll/jabber/jabberwocky.html) by Lewis Carroll:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def clean_words (text):\n",
      "  return filter(lambda x: len(x) > 0, re.sub(\"[^A-Za-z]\", \" \", text).split(\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jabber_text = \"\"\"\n",
      "`Twas brillig, and the slithy toves\n",
      "  Did gyre and gimble in the wabe:\n",
      "All mimsy were the borogoves,\n",
      "  And the mome raths outgrabe.\n",
      "\n",
      "\"Beware the Jabberwock, my son!\n",
      "  The jaws that bite, the claws that catch!\n",
      "Beware the Jubjub bird, and shun\n",
      "  The frumious Bandersnatch!\"\n",
      "He took his vorpal sword in hand:\n",
      "  Long time the manxome foe he sought --\n",
      "So rested he by the Tumtum tree,\n",
      "  And stood awhile in thought.\n",
      "And, as in uffish thought he stood,\n",
      "  The Jabberwock, with eyes of flame,\n",
      "Came whiffling through the tulgey wood,\n",
      "  And burbled as it came!\n",
      "One, two! One, two! And through and through\n",
      "  The vorpal blade went snicker-snack!\n",
      "He left it dead, and with its head\n",
      "  He went galumphing back.\n",
      "\"And, has thou slain the Jabberwock?\n",
      "  Come to my arms, my beamish boy!\n",
      "O frabjous day! Callooh! Callay!'\n",
      "  He chortled in his joy.\n",
      "\n",
      "`Twas brillig, and the slithy toves\n",
      "  Did gyre and gimble in the wabe;\n",
      "All mimsy were the borogoves,\n",
      "  And the mome raths outgrabe.\n",
      "\"\"\"\n",
      "\n",
      "jabber_words = clean_words(jabber_text.lower())\n",
      "print \"full:\", jabber_words\n",
      "\n",
      "jabber_uniq = sorted(set(jabber_words))\n",
      "print \"uniq:\", jabber_uniq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Problem:** Now let's use that data set with [HyperLogLog](http://en.wikipedia.org/wiki/HyperLogLog) to implement a probabilistic cardinality counter..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import hyperloglog\n",
      "\n",
      "# accept 1% counting error\n",
      "hll = hyperloglog.HyperLogLog(0.01)\n",
      "\n",
      "for word in jabber_words:\n",
      "  hll.add(word)\n",
      "\n",
      "print \"prob count %d, true count %d\" % (len(hll), len(jabber_uniq))\n",
      "print \"observed error rate %0.2f\" % (abs(len(hll) - len(jabber_uniq)) / float(len(jabber_uniq)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Great, those results show how the bounded error rate is working as expected."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Problem:** Next we'll use [Count-min sketch](http://en.wikipedia.org/wiki/Count%E2%80%93min_sketch) for frequency summaries, to implement a probabilistic [word count](http://en.wikipedia.org/wiki/Word_count)..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from countminsketch import CountMinSketch\n",
      "\n",
      "# table size=1000, hash functions=10\n",
      "cms = CountMinSketch(1000, 10)\n",
      "\n",
      "for word in jabber_words:\n",
      "  cms.add(word)\n",
      "\n",
      "wc = [(word, cms[word],) for word in jabber_uniq]\n",
      "\n",
      "from operator import itemgetter\n",
      "\n",
      "for pair in sorted(wc, key=itemgetter(1), reverse=True):\n",
      "  print pair"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bokay, that was hella simpler than writting 2000 lines of Java based on Yet-Another-Hadoop-Nightmare (YAHN)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Problem:** Next, let's use a [Bloom filter](http://en.wikipedia.org/wiki/Bloom_filter) for approximate membership queries... In this case, we'll compare text from a local Bash script `install.sh` to see if it has words intersecting with *Jabberwocky*?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybloom import BloomFilter\n",
      "\n",
      "bf = BloomFilter(capacity=1000, error_rate=0.001)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for word in jabber_words:\n",
      "  bf.add(word)\n",
      "\n",
      "intersect = set([])\n",
      "\n",
      "with open(\"../install.sh\") as f:\n",
      "  for line in f:\n",
      "    for word in clean_words(line.strip().lower()):\n",
      "      if word in bf:\n",
      "        intersect.add(word)\n",
      "\n",
      "print intersect"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is just a start. Even so, not so many programmers can claim that they have written and run code that takes advantage of probabilistic data structures. You have."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Installation notes:*\n",
      "\n",
      "  * [HyperLogLog](https://github.com/svpcom/hyperloglog)\n",
      "  * [CountMinSketch](https://github.com/rafacarrascosa/countminsketch)\n",
      "  * [pybloom](https://pypi.python.org/pypi/pybloom/1.0.2)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}